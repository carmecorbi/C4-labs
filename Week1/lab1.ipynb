{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Planar transformations and image rectification\n",
    "\n",
    "The two main goals of this first lab are the following:\n",
    "\n",
    "1) Get more familiar with the hierarchy of 2D transformations. <br>\n",
    "\n",
    "2) Image rectification: Removal of the projective distortion of an image of a planar object.\n",
    "\n",
    "This notebook combines some text cells (Markdown cells) and code cells. Some parts of the code need to be completed. All tasks you need to complete are marked in <span style='color:Green'> green.  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Image transformations**\n",
    "\n",
    "In this first part of the lab you will apply different types of 2D transformations to a given image. For that, you first need to create a function that applies a homography to an image.\n",
    "\n",
    "<span style='color:Green'> - Create the function  *apply_H* that gets as input a homography and\n",
    "an image and returns the image transformed by the homography. </span>\n",
    "\n",
    "Note: The size of the transformed image has to be automatically set so that it contains the whole transformed image.\n",
    "You will need to interpolate the image values at some points, for that,\n",
    "you may use the function *scipy.ndimage.map_coordinates*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from scipy.ndimage import map_coordinates\n",
    "from numpy import linalg as LA\n",
    "from math import ceil\n",
    "from utils import line_draw, plot_img\n",
    "\n",
    "def apply_H(I, H):\n",
    "    \n",
    "    # complete ...\n",
    " \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.1 Similarities**\n",
    "\n",
    "<span style='color:Green'> - Complete the code below by generating a matrix H that produces a similarity transformation. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H = ... # complete ...\n",
    "\n",
    "img_path = \"./Data/0005_s.png\"\n",
    "I = Image.open(img_path)\n",
    "I_sim = apply_H(np.array(I), H)\n",
    "\n",
    "plot_img(I)\n",
    "plot_img(I_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2 Affinities**\n",
    "\n",
    "<span style='color:Green'> - Complete the code below by generating a matrix H that produces an affine transformation.  </span>\n",
    "\n",
    "<span style='color:Green'> - Decompose the affinity in four transformations: two\n",
    "rotations, a scale, and a translation (you may use function *numpy.linalg.svd* for that).  </span>\n",
    "\n",
    "<span style='color:Green'> - Verify that the product of the four previous transformations\n",
    "produces the same matrix H as above.  </span>\n",
    "\n",
    "<span style='color:Green'> - Verify that the proper sequence of the four previous\n",
    "transformations, applied over the image `I` **one by one**, produces the same transformed image as before.  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H = ... # complete\n",
    "\n",
    "I_aff = apply_H(np.array(I), H)\n",
    "\n",
    "plot_img(I)\n",
    "plot_img(I_aff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.3 Projective transformations (Homographies)**\n",
    "\n",
    "<span style='color:Green'> - Complete the code below by generating a matrix H that produces a projective transformation.  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H = ... # complete\n",
    "\n",
    "I_proj = apply_H(np.array(I), H)\n",
    "\n",
    "plot_img(I)\n",
    "plot_img(I_proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Affine Rectification**\n",
    "\n",
    "This step is needed in order to rectify an image in a stratified way, where we first perform affine rectification (current section) and then metric rectification (Section 3).\n",
    "\n",
    "### **2.1 Vanishing points estimated semi-automatically**\n",
    "\n",
    "First, we will perform affine rectification by computing the vanishing points in a semi-automatic way. Line segments in the image will be detected automatically and then pairs of segments corresponding to imaged parallel lines will be manually selected. The segments are detected by the Line Segment Detector algorithm (paper [1], demo and code available in [2]). The result of this algorithm in the images of interest is already provided. The initial and final points of each detected segment are provided in a text file. The code below shows how to read the corresponding points for a certain segment given its index.  \n",
    "\n",
    "[1] R. Grompone von Gioi, J. Jakubowicz, J.-M. Morel, G. Randall. LSD: a Line Segment Detector. , Image Processing On Line, 2, , pp. 35â€“55, 2012.\n",
    "\n",
    "[2] http://www.ipol.im/pub/art/2012/gjmr-lsd/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images and lines\n",
    "img_path = \"./Data/0000_s.png\"\n",
    "I = Image.open(img_path)\n",
    "\n",
    "lines_path = \"./Data/0000_s_info_lines.txt\"\n",
    "A = np.loadtxt(lines_path)\n",
    "\n",
    "# points of interest\n",
    "i = 423 # line index (starting from 0)\n",
    "p1 = [A[i, 0], A[i, 1], 1] # initial point in line i\n",
    "p2 = [A[i, 2], A[i, 3], 1] # final point in line i\n",
    "i = 239\n",
    "p3 = [A[i, 0], A[i, 1], 1]\n",
    "p4 = [A[i, 2], A[i, 3], 1]\n",
    "i = 711\n",
    "p5 = [A[i, 0], A[i, 1], 1]\n",
    "p6 = [A[i, 2], A[i, 3], 1]\n",
    "i = 564\n",
    "p7 = [A[i, 0], A[i, 1], 1]\n",
    "p8 = [A[i, 2], A[i, 3], 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Green'> - Compute the lines l1, l2, l3, l4, that pass through the different pairs of points.  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1, l2, l3, l4 = # complete ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the chosen lines in the image\n",
    "canv = ImageDraw.Draw(I)\n",
    "point_color = (0, 0, 255)\n",
    "line_draw(l1, canv, I.size)\n",
    "line_draw(l2, canv, I.size)\n",
    "line_draw(l3, canv, I.size)\n",
    "line_draw(l4, canv, I.size)\n",
    "\n",
    "# The displayed lines will alter image I so we have to reopen the original image after the plot\n",
    "plot_img(I)\n",
    "I = Image.open(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Green'> - Compute the homography that affinely rectifies the image. </span>\n",
    "\n",
    "<span style='color:Green'> - Compute the transformed lines lr1, lr2, lr3, lr4 and\n",
    "      show the transformed lines in the transformed image. </span>\n",
    "      \n",
    "<span style='color:Green'> - To evaluate the results, compute the angle between the different pair \n",
    "      of lines before and after the image transformation. </span>\n",
    "      \n",
    "<span style='color:Green'> - Verify, experimentally, that the cross-ratio is preserved after the image rectification (you may choose the endpoints of some detected line segments). </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2 Vanishing points estimated automatically** \n",
    "\n",
    "The vanishing points in an image can be estimated automatically. In this lab, we will use the orthogonal vanishing points estimated by the technique proposed in [3] (code available in [4]), which actually uses the line segments estimated with the LSD algorithm [1] used before.\n",
    "\n",
    "In this section, we will work with the image 'friends.jpeg'. The estimated vanishing points obtained by [3] are provided in the file 'friends_vps.out' (see code below for more details).\n",
    "\n",
    "[3] Xiaohu Lu, Jian Yao, Haoang Li, Yahui Liu. 2-Line Exhaustive Searching for Real-Time Vanishing Point Estimation in Manhattan World. IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2017.\n",
    "\n",
    "[4] https://github.com/rayryeng/XiaohuLuVPDetection\n",
    "\n",
    "<span style='color:Green'> - Perform affine rectification of this image using the appropriate vanishing points automatically detected. **Justify your choice** of vanishing points. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize image 'friends.jpeg'\n",
    "\n",
    "# Visualize image 'friends_vps.jpeg' which shows the different line segments detected by LSD [1] and groups\n",
    "# them in three different colors according to the different vanishing points they have been associated.\n",
    "\n",
    "# Load the three orthogonal vanishing points from image 'friends.jpeg' (estimated by [3,4])\n",
    "vps = np.loadtxt('./Data/friends_vps.out', delimiter=',')\n",
    "# 'vps' is a numpy array where each row is a vanishing point and each column is a coordinate.\n",
    "# The first, second and third rows in 'vps' correspond to the vanishing points corresponding to,\n",
    "# respectively, red, green, and blue directions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Metric Rectification**\n",
    "\n",
    "### **3.1 Metric rectification after the affine rectification (stratified solution)**\n",
    "\n",
    "We will work with image 0000.\n",
    "\n",
    "<span style='color:Green'> - Write the code that performs the metric rectification (after the affine rectification). </span>\n",
    "\n",
    "As qualitative evaluation method you can display the images (before and after the metric rectification) with the chosen lines printed on it.\n",
    "      \n",
    "<span style='color:Green'> - Compute the angles between the pair of lines before and after rectification. Comment the result. </span>\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Affine and Metric Rectification of the left facade of image 0001**\n",
    "\n",
    "<span style='color:Green'> - Write the code that rectifies the left facade of image 0001 with\n",
    "      the stratified method.  </span>\n",
    "      \n",
    "Note: For a better visualization of the result crop the initial image so that only the left facade is visible.\n",
    "\n",
    "<span style='color:Green'> - Show the (properly) transformed lines that are used in every step.  </span>\n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. OPTIONAL: Metric Rectification in a single step**\n",
    "\n",
    "<span style='color:Green'> - Write the code that performs metric rectification of the white facade of image 0000 in a single step (algorithm pages 55-57, Hartley-Zisserman book). </span>\n",
    "\n",
    "Note: Use 5 pairs of orthogonal lines. You may consider that windows are square."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
